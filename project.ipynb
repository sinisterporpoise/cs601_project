{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6913d134-b3b2-4db2-a2ed-f57166a6f568",
   "metadata": {},
   "source": [
    "## CS 601 Project\n",
    "\n",
    "A last ditch attempt for a course that should have had more assignments broken into smaller chunks.  But let's be honest, I still needed to pay more attention to deadlines, even though some things were not my fault.\n",
    "\n",
    "### Date Set Chosen\n",
    "     For this data set I have chosen a a wine quality survey with 14 features and 12,000 samples or 12 features and 14,000 samples. Either way,  it should meet the requirements.\n",
    "\n",
    "### Purpose\n",
    "    To build a random forsest from scratch. I reserve the right to  test the model later using sklearn's methods.\n",
    "\n",
    "\n",
    "### Student Infomation\n",
    "Lara Landis\n",
    "CS601\n",
    "Majid Ashfar\n",
    "26 March 2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce0ce9c-5fc6-4651-93f5-f0b335a7fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import default_rng\n",
    "from  matplotlib import pyplot as plt\n",
    "\n",
    "rng = default_rng(110)\n",
    "np.set_printoptions(precision=5, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76871c67-4f1d-4604-be0c-e21bf31220f2",
   "metadata": {},
   "source": [
    "## Step 1: Dataset Selection and Preprocessing\n",
    "\n",
    "    Choose a suitable dataset that meets the above criteria.\n",
    "    Download and load the dataset into your Python environment.\n",
    "    Perform necessary preprocessing (handle missing values, encode categorical features, normalization/scaling, train-test split).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31e362d-3bc9-4393-bdc9-b032f8357d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll leave these here for later, but leave them commented out to avoid the temptation\n",
    "# import sklearn.mettrics\n",
    "# from sklearn.model import train_test_split\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97eb1e1-f296-4ce4-8c8c-ae3773d409aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"winequality-white.csv\", sep=\";\")\n",
    "# The reason for using the separator clause is because the white wine is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a108a78c-1226-49ac-8241-71490b0aac55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the data some\n",
    "df.fillna(0)     # Make sure there are no NaNs\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dbf0232-6f1b-475f-b5d8-65cd4b95018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we neeed to split our training data and our test data into different samples, this is one way to do this. We could\n",
    "# also us sklearn.train_test_spllit.\n",
    "train_data = df.iloc[0:int(np.floor(df.shape[0]* .65)), :]\n",
    "test_data = df.iloc[int(np.floor(df.shape[0] * .65))+1:, :]\n",
    "# Note, we actualy don't need to do any of this.\n",
    "np.set_printoptions(precision = 5, suppress = True)   # No scientific notation, we don't need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f5f3b5-8932-4c49-b865-f870422c6ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817bf77e-4bfd-43b3-86ee-436e6b5b8493",
   "metadata": {},
   "source": [
    "# Step 2: Implementing the Random Forest Classifier\n",
    "\n",
    "    Implement a Random Forest classification algorithm entirely from scratch, without using pre-built libraries like Scikit-learn.\n",
    "    Your implementation should allow specifying parameters, including:\n",
    "            * Number of trees\n",
    "            - Depth threshold\n",
    "            - Number of samples per split \n",
    "            - Number of samples per leaf node\n",
    "            - Criterion for determining the best feature split (Gini impurity or Entropy)\n",
    "            - Optional: Any other parameter that you think could be interesting to add\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e45c0f1-d8e0-4d31-945e-9148f9dddbef",
   "metadata": {},
   "source": [
    "### Bootstrap Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da38353-604d-415e-ac9a-75db5c4bce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will produce our bootstrap sample for training. We start by  passing the data frame into it, creating a new list\n",
    "# for sampled_data, and then we go through each sample, making assign a random column to the data. This should be different for\n",
    "# each particular run.\n",
    "\n",
    "def bootstrap(data):\n",
    "    n_samples = data.shape[0] \n",
    "    sampled_data = []\n",
    "    for i in range(n_samples):\n",
    "        random_index = np.random.randint(0,n_samples)\n",
    "        sampled_data.append(data[random_index])\n",
    "    return np.array(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a382c4-b8bc-4257-9008-f786b299629c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a12c40-4663-40ba-86af-6b0f84325c14",
   "metadata": {},
   "source": [
    "### OOB Samples \n",
    "Selecting out of  bag will work similrly to the bootstrap process, but for this we want the ones not selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb92a5b-75c5-4ee2-9578-a3ee845fc7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will create both the boot strap and the out of bg samples in one swoop. The first line creates\n",
    "# the boostrap, it hen gets the nuber of unique lines, it creates a list to storte the samples in, and than it goes through\n",
    "# each sample, then it looks to see if any item in the data sample currently being considered match \n",
    "\n",
    "def bs_oob_samples(data):\n",
    "    bs = bootstrap(data)\n",
    "    nuique_bs_samples = np.unique(bs, axis=0)\n",
    "    oob_samples = []\n",
    "    for sample in data:\n",
    "        if sum(np.all(sample == nuique_bs_samples, axis= 1)) == 0:\n",
    "            oob_samples.append(sample)\n",
    "    return bs,np.array(oob_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d187c25-5761-49a8-8799-d4fcfc74c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,oob = bs_oob_samples(df.to_numpy())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d78ddc2-d19d-4474-adf9-6ec279ce8f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.7 ,  0.3 ,  0.35, ...,  0.54,  9.4 ,  6.  ],\n",
       "       [ 6.8 ,  0.32,  0.39, ...,  0.35, 12.1 ,  6.  ],\n",
       "       [ 5.4 ,  0.5 ,  0.13, ...,  0.88, 13.5 ,  7.  ],\n",
       "       ...,\n",
       "       [ 5.6 ,  0.34,  0.3 , ...,  0.49, 11.1 ,  6.  ],\n",
       "       [ 7.8 ,  0.43,  0.49, ...,  0.35, 11.3 ,  6.  ],\n",
       "       [ 8.2 ,  0.4 ,  0.48, ...,  0.52,  9.4 ,  5.  ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "423f23b5-6973-4ae8-be8f-f362a738ad6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.1 ,  0.22,  0.43, ...,  0.45, 11.  ,  6.  ],\n",
       "       [ 6.6 ,  0.16,  0.4 , ...,  0.52, 12.4 ,  7.  ],\n",
       "       [ 6.5 ,  0.31,  0.14, ...,  0.5 ,  9.5 ,  5.  ],\n",
       "       ...,\n",
       "       [ 6.2 ,  0.21,  0.29, ...,  0.5 , 11.2 ,  6.  ],\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8066063c-959c-4287-bfd8-c473a6ceb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Note: It will be necessary to go back later and remove this part\n",
    "def create_tree(data, max_depth = 3, min_samples_per_leaf = 5, criterion=\"gini\"):\n",
    "    X = data[:,0:-1]      # syphon the data we will use for predication features\n",
    "    y = data[:,-1]        # set aside this for predictions\n",
    "    dt = DecisionTreeClassifier()   # To be honest I'm not sure about using this, but it was used in the exmple code\n",
    "    dt.fit(X,y)                     # Finally fit the data so we can make prediction\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e191e935-8386-47df-b6f0-16cd99a39671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = create_tree(bs)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a28bab91-f7f3-49ee-9f62-0b31ac5556f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oob.shape\n",
    "bs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5eff12c-ee5e-4798-88dc-3c763e0114ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.]\n",
      "[7.]\n"
     ]
    }
   ],
   "source": [
    "print(dt.predict(oob[1:2, :-1]))  # Did we get the prediction?\n",
    "print(oob[1:2, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67edc49-5d38-4bb0-80fc-34e113c2a5d0",
   "metadata": {},
   "source": [
    "## Metric Used\"\n",
    "\n",
    "For now, gini impurity is being used.  This lets us know the chances that a random element is inorrect or as Victor Zhou states on his blog, \"Gini Impurity is the probability of incorrectly classifying a randomly chosen element in the dataset if it were randomly labeled according to the class distribution in the dataset.\" Personally, I feel like entropy would be a better choice on this because it would likely result in better results over all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b52d05-1383-47e0-a1cf-fa23016c3d15",
   "metadata": {},
   "source": [
    "### Building the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29dd13a9-702b-46af-a0b7-babd1a9a9a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_rf(data, depth =3, n_features = 10, leaf_nodes = 7, n_trees = 3):\n",
    "    trees = []\n",
    "    bs,oob = bs_oob_samples(data)\n",
    "    for i in range(n_trees):\n",
    "            # Get the last column and return it for evaluation\n",
    "        n_features = bs.shape[1] - 1 # number of features excluding target col\n",
    "        n_random_features = n_features        # For a small data set, we likely don't need this.\n",
    "        random_selected_features =  rng.choice(n_features,n_random_features,replace = False)     # Select a new feature each time.                                                                                              # Replcae = False means new feature each time\n",
    "        random_features_with_target = np.append(random_selected_features,-1) # add target index to selected features\n",
    "        sub_data = bs[:,random_features_with_target]   # Create a subset of the bs samples\n",
    "       \n",
    "        dt = create_tree(sub_data, depth, leaf_nodes)                                            # Return the tree we need\n",
    "        sub_oob = oob[:,random_selected_features] # Create a subset of the oob samples\n",
    "        trees = dt.predict(sub_oob)         # Return the predictions since that is what we are interested in\n",
    "    actual_values = oob[:, -1]\n",
    "    # We need to return sub_oob for comparison\n",
    "    return actual_values, trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e17458c-7748-4357-b12b-ab3ddaa0ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_results(data, n_trees = 3):\n",
    "    final_tree = []                                # Empty array to store the last tiems\n",
    "    for i in range(len(data)):    \n",
    "        acc = 0                                    # Set this to 0 after the start of outer loop because we need aavareages\n",
    "        for j in range(n_trees):\n",
    "            acc += data[i]\n",
    "        final_tree.append(int(acc/n_trees))              # get the average and append it to the list\n",
    "\n",
    "    return np.array(final_tree)                    # Return our tree as an numpy array for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "391417d6-b496-4414-a89a-f63940d86a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values, trained = sample_rf(bs,5, 7, 8)  ## Train the data set\n",
    "results = forest_results(trained)           # Generate the actual random forest since the random forest function is lacking.\n",
    "                                            # Note need to merge this into actual function or use it as a helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad1341b2-bf96-437e-8876-181caa756f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 6 7 7 7 5 6 5 5 5 7 6 5 7 7 6 6 7 6 4 6 6 8 7 5 6 6 6 8 5 7 6 6 8 4 6\n",
      " 4 7 5 6 6 5 6 6 4 6 6 5 6 7 6 6 5 7 7 6 6 6 5 5 7 6 7 7 5 4 5 5 8 5 5 5 6\n",
      " 6 6 6 5 7 5 6 6 6 6 6 5 6 7 7 7 6 6 8 6 6 6 6 6 7 6 7 6 6 6 6 5 5 5 7 5 5\n",
      " 5 5 6 8 6 5 6 6 6 5 7 4 5 6 5 5 8 5 6 5 6 6 4 7 5 6 5 5 5 6 6 6 7 6 6 6 4\n",
      " 6 6 6 6 6 5 6 7 6 8 6 6 7 5 6 7 7 6 6 7 7 6 8 6 8 8 5 6 6 6 4 5 6 6 5 6 6\n",
      " 6 7 6 6 6 6 5 5 7 6 6 7 6 6 5 5 6 6 5 5 5 7 7 7 5 7 7 6 6 5 8 7 6 7 7 6 7\n",
      " 7 5 6 6 6 6 6 7 7 7 5 6 5 8 7 7 6 7 6 5 5 6 5 5 6 6 5 7 6 4 6 5 6 5 5 7 5\n",
      " 6 6 8 7 5 7 5 5 6 4 4 6 5 7 7 5 6 6 6 6 6 6 5 6 6 7 5 8 5 5 7 6 5 6 8 6 5\n",
      " 6 6 7 7 9 6 5 5 7 6 5 5 5 7 6 5 4 6 5 5 4 6 5 7 8 6 7 5 7 7 6 5 6 7 6 6 7\n",
      " 7 5 7 5 5 5 6 5 6 5 5 7 7 7 4 5 5 6 7 5 5 5 6 6 6 6 5 5 6 6 6 4 7 5 5 7 8\n",
      " 6 7 4 7 5 5 7 7 6 7 5 6 5 6 4 6 5 6 5 7 7 7 5 6 7 8 6 6 7 6 7 6 5 9 8 5 5\n",
      " 8 6 5 6 5 7 6 5 5 6 7 6 7 6 6 6 7 6 6 6 5 6 7 5 7 7 5 6 5 5 6 6 5 5 7 5 6\n",
      " 6 5 5 5 5 6 7 5 6 7 6 5 6 5 6 6 6 6 7 5 5 6 6 8 7 6 6 6 6 6 6 6 5 7 7 7 5\n",
      " 4 5 6 6 8 5 6 4 4 6 7 7 3 6 7 5 6 6 4 5 5 6 3 6 5 4 6 6 6 6 6 7 6 6 6 6 8\n",
      " 5 5 7 5 6 5 4 6 6 6 6 7 7 7 6 6 8 6 5 5 6 7 6 7 6 5 5 8 7 6 4 6 6 5 5 7 6\n",
      " 5 6 5 6 5 7 6 5 6 7 5 6 6 6 5 7 6 6 8 6 8 6 8 7 7 6 5 5 6 6 8 7 6 6 6 5 6\n",
      " 6 5 5 6 6 4 5 6 5 6 8 6 5 5 6 6 5 6 6 5 6 6 5 5 6 5 6 6 6 7 8 6 7 6 7 6 6\n",
      " 6 4 6 5 6 5 6 6 6 7 5 6 7 6 7 6 6 6 5 6 5 6 7 5 7 5 3 4 5 7 7 5 5 6 5 5 7\n",
      " 6 4 5 5 6 6 6 6 7 6 7 5 6 5 7 6 8 5 6 8 5 5 6 6 7 5 6 3 7 9 7 8 6 7 7 6 6\n",
      " 5 5 6 7 6 6 5 6 4 7 7 7 6 6 7 5 5 5 6 5 6 7 7 7 7 7 6 6 6 6 6 5 6 5 6 8 6\n",
      " 6 5 5 6 6 7 5 5 7 6 6 6 6 6 7 6 5 7 5 7 5 8 6 6 6 6 6 8 8 6 7 7 5 5 5 3 7\n",
      " 6 5 7 6 6 5 5 8]\n",
      "[5. 7. 6. 7. 5. 7. 7. 5. 6. 6. 6. 6. 6. 6. 7. 7. 6. 5. 6. 7. 4. 6. 6. 6.\n",
      " 6. 7. 6. 6. 6. 7. 6. 5. 6. 6. 6. 5. 5. 5. 5. 5. 6. 5. 6. 6. 5. 3. 6. 5.\n",
      " 5. 8. 6. 5. 5. 6. 6. 7. 6. 5. 7. 4. 6. 6. 5. 7. 7. 5. 7. 5. 6. 6. 6. 5.\n",
      " 5. 7. 6. 7. 5. 7. 8. 5. 8. 8. 5. 6. 6. 7. 5. 6. 7. 7. 6. 6. 5. 5. 7. 6.\n",
      " 6. 6. 7. 6. 4. 5. 6. 6. 5. 5. 5. 5. 7. 5. 5. 5. 3. 6. 6. 5. 5. 6. 6. 6.\n",
      " 5. 6. 6. 5. 5. 6. 6. 7. 5. 7. 5. 6. 5. 5. 7. 5. 6. 6. 6. 6. 5. 7. 7. 6.\n",
      " 6. 5. 6. 5. 7. 6. 6. 6. 8. 4. 6. 6. 6. 7. 6. 5. 7. 6. 6. 6. 6. 6. 6. 7.\n",
      " 5. 6. 5. 6. 8. 5. 6. 6. 7. 5. 5. 5. 6. 6. 7. 6. 5. 5. 7. 6. 6. 5. 5. 5.\n",
      " 6. 6. 6. 5. 7. 6. 7. 6. 5. 6. 7. 5. 5. 5. 6. 6. 7. 6. 6. 7. 6. 6. 6. 6.\n",
      " 7. 6. 6. 6. 5. 6. 9. 6. 6. 6. 7. 6. 6. 6. 7. 6. 5. 8. 6. 6. 6. 6. 6. 5.\n",
      " 5. 5. 6. 6. 6. 6. 5. 5. 5. 6. 6. 6. 6. 4. 7. 5. 6. 7. 7. 7. 6. 6. 8. 5.\n",
      " 7. 5. 5. 7. 4. 6. 5. 6. 7. 7. 5. 5. 6. 6. 5. 6. 4. 5. 5. 6. 6. 6. 6. 5.\n",
      " 5. 6. 5. 5. 6. 9. 6. 5. 6. 5. 6. 7. 7. 6. 5. 6. 7. 5. 5. 7. 6. 5. 6. 6.\n",
      " 4. 8. 5. 6. 5. 8. 5. 7. 7. 6. 6. 5. 5. 7. 6. 5. 6. 6. 6. 6. 7. 6. 7. 6.\n",
      " 5. 5. 5. 6. 6. 6. 5. 6. 6. 6. 7. 6. 5. 5. 7. 7. 5. 5. 5. 6. 5. 7. 5. 4.\n",
      " 6. 6. 6. 6. 6. 6. 6. 7. 6. 5. 7. 5. 6. 7. 5. 6. 6. 7. 5. 6. 5. 6. 6. 4.\n",
      " 6. 6. 6. 7. 4. 5. 6. 7. 5. 5. 7. 6. 5. 6. 5. 5. 7. 5. 5. 6. 9. 5. 4. 8.\n",
      " 6. 4. 5. 5. 8. 6. 5. 6. 7. 7. 5. 7. 6. 5. 6. 5. 6. 5. 6. 7. 6. 7. 5. 8.\n",
      " 7. 7. 6. 6. 5. 5. 6. 4. 5. 6. 5. 5. 5. 5. 6. 5. 6. 5. 6. 5. 6. 6. 6. 5.\n",
      " 6. 6. 5. 5. 7. 6. 7. 7. 5. 6. 6. 6. 7. 5. 7. 5. 8. 6. 5. 6. 5. 6. 7. 6.\n",
      " 6. 5. 5. 8. 7. 6. 6. 6. 5. 6. 5. 6. 6. 5. 6. 6. 6. 5. 6. 5. 5. 4. 6. 5.\n",
      " 6. 5. 5. 6. 6. 5. 6. 6. 5. 6. 5. 5. 5. 6. 6. 6. 5. 3. 5. 5. 4. 5. 6. 6.\n",
      " 6. 7. 7. 7. 7. 6. 7. 5. 7. 6. 6. 7. 6. 7. 6. 5. 6. 7. 7. 6. 5. 5. 6. 5.\n",
      " 5. 5. 7. 6. 5. 5. 6. 6. 6. 6. 6. 5. 6. 5. 6. 5. 5. 6. 6. 5. 6. 6. 5. 6.\n",
      " 5. 5. 6. 7. 5. 5. 7. 6. 6. 5. 6. 5. 5. 6. 5. 5. 6. 5. 7. 6. 6. 4. 5. 8.\n",
      " 6. 5. 6. 6. 5. 6. 6. 6. 5. 8. 6. 6. 6. 6. 6. 6. 5. 6. 6. 5. 6. 7. 6. 5.\n",
      " 6. 6. 7. 5. 5. 6. 5. 6. 8. 8. 5. 5. 6. 6. 6. 7. 5. 7. 6. 7. 6. 6. 6. 6.\n",
      " 7. 5. 6. 4. 8. 6. 5. 6. 4. 6. 6. 7. 7. 7. 6. 6. 6. 6. 5. 5. 4. 6. 6. 6.\n",
      " 6. 6. 8. 6. 6. 6. 6. 6. 5. 5. 6. 5. 5. 6. 5. 5. 5. 5. 7. 6. 5. 6. 5. 6.\n",
      " 6. 8. 5. 6. 6. 7. 6. 6. 5. 8. 8. 8. 6. 6. 6. 6. 6. 6. 6. 5. 5. 7. 5. 6.\n",
      " 5. 6. 5. 7. 7. 7. 6. 6. 6. 6. 7. 4. 6. 7. 4. 6. 7. 6. 6. 6. 6. 5. 5. 5.\n",
      " 7. 7. 5. 6. 7. 6. 7. 6. 5. 4. 6. 5. 5. 6. 5. 5. 5. 7. 6. 5. 6. 5. 6. 7.\n",
      " 5. 7. 6. 7. 5. 5. 5. 4. 6. 7. 6. 7. 6. 6. 5. 6. 7.]\n"
     ]
    }
   ],
   "source": [
    "# Now that we've trained, let's see how it goes with our other data.actual_values, oob_preds = sample_rf(oob, 5, 7, 8)\n",
    "trained_results = np.array(forest_results(trained, 7))\n",
    "print(trained_results)\n",
    "print(actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24d13ee6-eb37-4855-9ca0-3ef593ed6c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1348,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oob[:, -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49f61663-1936-41d4-ac75-06341afe4bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465 465\n",
      "[6. 7. 5. 6. 6. 7. 6. 6. 4. 5. 6. 7. 4. 6. 5. 5. 6. 5. 4. 7. 5. 7. 4. 5.\n",
      " 5. 8. 4. 5. 5. 6. 7. 5. 6. 6. 5. 7. 5. 5. 6. 7. 6. 6. 5. 6. 6. 6. 6. 6.\n",
      " 6. 6. 6. 5. 7. 7. 5. 6. 6. 5. 5. 4. 5. 7. 5. 5. 6. 5. 5. 5. 6. 6. 6. 6.\n",
      " 7. 6. 7. 7. 7. 6. 7. 6. 6. 5. 6. 9. 6. 7. 4. 7. 6. 5. 5. 5. 4. 5. 7. 6.\n",
      " 6. 4. 5. 6. 7. 5. 6. 5. 5. 7. 6. 6. 5. 7. 4. 8. 7. 7. 6. 5. 5. 4. 4. 6.\n",
      " 6. 5. 5. 5. 7. 3. 7. 6. 7. 7. 5. 7. 6. 6. 6. 6. 7. 7. 6. 5. 5. 5. 6. 7.\n",
      " 4. 7. 7. 7. 6. 3. 7. 6. 5. 6. 6. 6. 5. 5. 6. 5. 7. 5. 6. 7. 6. 6. 6. 4.\n",
      " 6. 6. 5. 5. 7. 5. 5. 6. 7. 5. 6. 6. 5. 6. 6. 6. 6. 6. 6. 5. 6. 7. 5. 5.\n",
      " 6. 6. 6. 5. 6. 5. 6. 4. 6. 5. 6. 5. 5. 6. 7. 6. 5. 6. 6. 5. 6. 6. 5. 5.\n",
      " 6. 6. 6. 5. 5. 5. 5. 6. 4. 6. 7. 5. 7. 5. 5. 5. 5. 7. 6. 5. 5. 5. 5. 6.\n",
      " 5. 6. 6. 7. 7. 6. 7. 6. 6. 6. 7. 5. 6. 4. 6. 5. 6. 5. 6. 6. 5. 5. 6. 7.\n",
      " 5. 7. 5. 5. 6. 5. 5. 5. 4. 6. 6. 7. 5. 5. 7. 8. 8. 5. 7. 5. 5. 6. 5. 5.\n",
      " 5. 5. 6. 7. 5. 7. 6. 6. 6. 6. 6. 5. 5. 7. 7. 5. 6. 7. 5. 6. 6. 6. 8. 6.\n",
      " 5. 5. 5. 7. 6. 6. 5. 6. 6. 6. 7. 6. 6. 6. 7. 7. 7. 7. 6. 7. 7. 6. 5. 4.\n",
      " 8. 6. 7. 5. 5. 8. 6. 7. 6. 6. 6. 7. 6. 6. 6. 5. 4. 5. 7. 7. 5. 6. 6. 7.\n",
      " 8. 5. 6. 6. 5. 6. 7. 5. 5. 5. 6. 6. 5. 5. 7. 5. 7. 6. 6. 5. 5. 5. 5. 5.\n",
      " 7. 7. 6. 5. 6. 6. 8. 7. 7. 5. 6. 5. 7. 7. 6. 5. 6. 7. 6. 7. 5. 7. 7. 6.\n",
      " 5. 7. 7. 5. 6. 6. 5. 6. 6. 6. 6. 5. 6. 5. 6. 6. 6. 6. 6. 6. 7. 6. 7. 5.\n",
      " 6. 6. 6. 7. 5. 5. 6. 7. 6. 4. 6. 4. 6. 6. 5. 6. 5. 5. 8. 4. 5. 6. 6. 6.\n",
      " 5. 6. 6. 6. 5. 4. 6. 6. 7.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 6, 5, 7, 6, 5, 6, 5, 4, 7, 6, 6, 8, 7, 6, 6, 5, 5, 6, 7, 6, 7,\n",
       "       5, 6, 6, 7, 5, 5, 6, 6, 6, 5, 7, 7, 6, 7, 6, 5, 5, 6, 5, 5, 6, 8,\n",
       "       5, 8, 6, 7, 6, 5, 8, 5, 6, 6, 5, 6, 6, 6, 6, 5, 7, 7, 6, 6, 6, 6,\n",
       "       5, 5, 6, 5, 5, 5, 6, 6, 5, 5, 4, 5, 4, 6, 6, 5, 6, 7, 6, 6, 6, 5,\n",
       "       6, 5, 6, 5, 4, 7, 6, 6, 7, 6, 7, 5, 5, 6, 6, 6, 5, 6, 4, 5, 5, 5,\n",
       "       5, 6, 7, 6, 6, 6, 6, 5, 7, 5, 6, 5, 5, 5, 7, 6, 7, 5, 8, 8, 5, 6,\n",
       "       6, 6, 6, 6, 6, 8, 5, 6, 5, 5, 6, 6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 7,\n",
       "       6, 6, 6, 5, 7, 5, 8, 5, 6, 4, 6, 5, 6, 6, 6, 5, 6, 4, 6, 6, 7, 6,\n",
       "       6, 6, 5, 7, 6, 6, 6, 5, 6, 6, 6, 5, 6, 5, 6, 5, 6, 6, 6, 5, 6, 6,\n",
       "       8, 6, 5, 6, 4, 6, 5, 5, 6, 7, 6, 7, 6, 5, 6, 6, 5, 7, 6, 6, 6, 5,\n",
       "       5, 6, 7, 6, 6, 6, 6, 6, 6, 7, 6, 5, 5, 6, 6, 6, 5, 6, 6, 6, 7, 7,\n",
       "       6, 7, 8, 6, 6, 7, 5, 7, 6, 5, 6, 5, 6, 6, 7, 6, 6, 7, 6, 5, 4, 6,\n",
       "       5, 6, 5, 5, 7, 6, 6, 6, 6, 6, 5, 6, 3, 5, 6, 3, 3, 5, 5, 6, 6, 5,\n",
       "       5, 7, 6, 5, 6, 7, 5, 5, 5, 6, 6, 4, 7, 6, 7, 5, 6, 5, 6, 7, 7, 6,\n",
       "       6, 7, 6, 6, 6, 7, 7, 7, 6, 8, 7, 6, 6, 5, 6, 5, 6, 6, 7, 5, 6, 6,\n",
       "       6, 7, 7, 7, 6, 5, 7, 5, 7, 6, 5, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7,\n",
       "       6, 6, 6, 6, 6, 5, 6, 5, 7, 5, 6, 7, 5, 6, 6, 6, 7, 6, 6, 6, 6, 5,\n",
       "       8, 5, 5, 6, 5, 5, 6, 5, 6, 5, 6, 6, 6, 5, 5, 6, 7, 7, 7, 5, 5, 5,\n",
       "       7, 5, 6, 5, 6, 6, 6, 7, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6,\n",
       "       6, 6, 6, 5, 6, 6, 6, 6, 7, 7, 8, 8, 7, 5, 7, 6, 6, 6, 5, 4, 5, 6,\n",
       "       7, 5, 6, 5, 7, 6, 7, 6, 5, 5, 7, 5, 5, 6, 5, 7, 6, 6, 6, 5, 5, 5,\n",
       "       6, 6, 6])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Now let's do wwhat we did with the trainign samples with the oob samples.\n",
    "oob_actual, oob_preds = sample_rf(oob, 5, 7, 8)\n",
    "oob_results = np.array(forest_results(oob_preds, 7))\n",
    "print(len(oob_actual), len(oob_results))\n",
    "print(oob_actual)\n",
    "oob_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50efbda-ccd6-4b21-b0b2-b3c767055441",
   "metadata": {},
   "source": [
    "# Step 3: Model Training, Evaluation, and Comparison\n",
    "\n",
    "    Train your implemented classifier using your training dataset.\n",
    "    Evaluate your model's performance on the test dataset using metrics such as accuracy, precision, recall, F1-score, and confusion matrix.\n",
    "    Also, train a Random Forest classifier using Scikit-learn (sklearn.ensemble.RandomForestClassifier) on the same training dataset.\n",
    "    Evaluate the Scikit-learn model's performance using the same metrics.\n",
    "    Compare the performance of your implemented classifier with the Scikit-learn model and discuss any observed differences and insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d98151b-701b-49ba-9b90-6db5a67f85ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's take a look at some data\n",
    "plt.scatter(oob_actual , oob_results, label = \"Diffrences between predictions and actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a6cc1-8d40-48fa-8239-0dcd47c6d874",
   "metadata": {},
   "source": [
    "# The graph...\n",
    " \n",
    "The graph's visualization isn't particularly helpful here. Let's take a look at some metrics to see how well oour classification\n",
    "model performed. Some of these metrics may not make much sense in terms of wine quality, particularly false positives for this since we're\n",
    "not classify between two things, but six. We'll look for accuracy, because the false positives and false negatives are meaningless on this set\n",
    "\n",
    "## Formula for REcall\n",
    "       TP/TP+FN of samples      (False negatives do not apply in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa4012b5-dca7-4999-9b2d-dc7e67d31ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False,  True, False,  True, False,  True,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False,  True, False,  True, False, False, False, False, False,\n",
       "        True, False,  True, False,  True, False, False, False,  True,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False,  True, False,  True, False, False,  True, False, False,\n",
       "        True,  True,  True, False, False, False, False,  True, False,\n",
       "       False,  True, False,  True,  True,  True, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True,  True,\n",
       "        True,  True, False,  True, False, False, False,  True,  True,\n",
       "       False,  True,  True, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "        True, False, False, False,  True, False,  True, False, False,\n",
       "       False, False, False,  True,  True,  True,  True,  True, False,\n",
       "        True, False, False, False,  True, False,  True,  True,  True,\n",
       "        True, False, False, False, False,  True,  True,  True, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False,  True,  True, False,  True, False,  True, False,  True,\n",
       "        True, False,  True, False,  True, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True, False, False,  True, False,\n",
       "        True, False, False, False, False, False,  True,  True, False,\n",
       "        True, False,  True, False, False,  True, False, False,  True,\n",
       "        True, False,  True, False, False, False, False, False,  True,\n",
       "        True, False,  True, False, False, False,  True, False, False,\n",
       "        True, False, False,  True, False,  True,  True, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False,  True, False, False, False, False,  True, False,\n",
       "       False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "       False, False, False, False, False, False,  True,  True,  True,\n",
       "       False,  True,  True, False, False,  True, False, False, False,\n",
       "        True,  True, False, False,  True,  True, False, False, False,\n",
       "        True,  True,  True, False, False, False,  True,  True,  True,\n",
       "       False, False, False, False, False,  True, False,  True, False,\n",
       "        True, False,  True,  True,  True, False,  True,  True,  True,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False,  True,  True, False,  True,  True, False, False, False,\n",
       "       False,  True,  True, False,  True, False,  True, False,  True,\n",
       "       False,  True, False,  True, False,  True, False, False,  True,\n",
       "        True, False,  True, False,  True,  True,  True, False,  True,\n",
       "        True, False,  True,  True,  True, False,  True,  True, False,\n",
       "       False, False,  True,  True, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False, False,  True,  True,\n",
       "       False,  True,  True, False,  True, False, False, False, False,\n",
       "       False,  True, False, False,  True, False,  True,  True,  True,\n",
       "       False, False,  True,  True, False, False, False,  True,  True,\n",
       "       False,  True, False,  True,  True, False])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = oob_actual == oob_results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8cbb772-3e28-4ef9-9ad1-a1312a5cd2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "0.43010752688172044 =  0.43010752688172044\n"
     ]
    }
   ],
   "source": [
    "np.sum(np.any(results)==True)\n",
    "# Okay, this isn't workiong like I want it to.\n",
    "print(type(results))\n",
    "# So let's do this the old fashioned way.\n",
    "results.tolist()\n",
    "counter = 0\n",
    "true_positives = 0\n",
    "true_negatives = 0\n",
    "for item in results:\n",
    "    if item == True:\n",
    "        true_positives += 1\n",
    "    if item == False:\n",
    "        true_negatives += 1\n",
    "    counter += 1\n",
    "print (f'{true_positives / (true_positives + true_negatives)} =  {true_positives/counter}')  # Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72cbdad6-4531-4517-8a21-6519fac36009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.01075268817204"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have true positives versus the entire array, which will give us the same thing as (TP + TN)/(TP+TN+FP+FN)\n",
    "# we can simplify are formula, since all negatives are true negatives and all positives are true positive, or should be for this \n",
    "# particular data set.\n",
    "\n",
    "accuracy = true_positives / (true_positives + true_negatives)\n",
    "accuracy * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ae9a0-1b1f-461e-905d-f0a0d432c873",
   "metadata": {},
   "source": [
    "## Evaluation`\n",
    "\n",
    "Our model has around a 43% accuracy rating using 10 features, which is the highest accuracy rating of the run doing it from scratch. We know need to invoke scikit learn to compare our model to the model it would come up with\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b188ac1e-3587-43d9-87f7-7b6c661a90aa",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ce4b7-1ee2-4a61-838e-ec2abdd540b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
